{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Tinkoff Финтех школа. осень 2018\n",
    "### Предсказание отклика клиента. Домашняя работа.\n",
    "\n",
    "Предсказание, что клиент согласится на предложение продукта банка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание (3 - 8 баллов)**\n",
    "\n",
    "Предсказать NPV. т.е. задача регрессии и label = 'npv'.\n",
    "\n",
    "Выбрать лучшие гиперпараметры для каждой из моделей:\n",
    "    - дерево решений\n",
    "    - случайный лес\n",
    "    - бустинг\n",
    "    \n",
    "Предсказать NPV на тестовой выборке. \n",
    "<br>Поменять DecisionTreeClassifier на DecisionTreeRegressor, аналогично с RandomForest.\n",
    "<br>В параметрах градиентного бустинга испольовать *'objective': 'binary'*.\n",
    "<br>Метрику качества использовать **R2** sklearn.metrics.r2_score.\n",
    "\n",
    "Файл с результатами (test_predict_m.csv) приложить к домашнему заданию.\n",
    "\n",
    "Все предсказания с `R2 score > 0` хотя бы одной моделью (из 3) получат 3 балла.\n",
    "<br>Далее ответы студентов упорядочиваются по R2 score.\n",
    "1. Топ-3 получают 5 дополнительных баллов.\n",
    "2. Следующие 3 получают 4 дополнительных балла.\n",
    "3. Следующие 6 получают 3 дополнительных балла.\n",
    "4. Следующие 10 получают 2 дополнительных балла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from collections import OrderedDict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = 'data'\n",
    "df = pd.read_csv(os.path.join(dump_path,'train_m.csv'))\n",
    "df_test = pd.read_csv(os.path.join(dump_path,'test_wo_labels_m.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_feats = ['add_base_flg', 's1_last_dates',  's1_prev_dates',  's1_request_flg', 'first_inc_call_dates', \n",
    "                   'first_out_call_dates', 's2_last_dates', 's2_prev_dates', 's2_request_flg', 'inc_call_cnt',\n",
    "                   'last_inc_call_dates', 'last_out_call_dates', 's3_last_dates','s3_prev_dates', 's3_request_flg',\n",
    "                   'out_call_cnt', 'prev_load_cnt', 'prev_load_dates', 'prev_s2s1', 'prev_s2s2', 'prev_s3s1', \n",
    "                   'prev_s3s2', 'prev_s1s1', 's2s1', 's2s2', 'skp_base_flg', 's3s1', 's3s2', 's1s1',\n",
    "                   'user_contact_base_flg', 's3_available_flg', 's2_available_flg', 's1_available_flg']\n",
    "\n",
    "categ_feats = ['utm_campaign', 'region', 'mob_provider', 'prev_load_status']\n",
    "\n",
    "label = 'npv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = dict([(f,LabelEncoder()) for f in categ_feats])\n",
    "for f in categ_feats:\n",
    "    df[f+'_le'] = le[f].fit_transform(df[f].astype(str))\n",
    "    \n",
    "feat_cols = continous_feats + [f + '_le' for f in categ_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.query('finish_dttm <  \"2018-03-30\"')\n",
    "df_valid = df.query('finish_dttm >= \"2018-03-30\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = df_train[feat_cols].fillna(df_train[feat_cols].mean())\n",
    "new_df_valid = df_valid[feat_cols].fillna(df_train[feat_cols].mean())\n",
    "new_df_train[label] = df_train[label]\n",
    "new_df_valid[label] = df_valid[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=10, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dc = DecisionTreeRegressor(max_depth=10)\n",
    "dc.fit(new_df_train[feat_cols],new_df_train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth 10.\n",
      "Decision tree on train sample. R2 0.045.\n",
      "Decision tree on valid sample. R2 -0.117.\n"
     ]
    }
   ],
   "source": [
    "train_pred = dc.predict(new_df_train[feat_cols])\n",
    "valid_pred = dc.predict(new_df_valid[feat_cols])\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(f'Tree depth {dc.tree_.max_depth}.')\n",
    "print(f'Decision tree on train sample. R2 {r2_score_train:.3f}.')\n",
    "print(f'Decision tree on valid sample. R2 {r2_score_valid:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01980438200464063\n",
      "\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2980}\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=10, max_features='sqrt',\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=2980,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "parameters_DecisionTree = {\n",
    "    'max_depth': np.arange(2,20,2),\n",
    "    'min_samples_leaf': np.exp(np.linspace(2,8,6)).astype(int),\n",
    "    'max_features': ['sqrt', 'log2', None], \n",
    "}\n",
    "\n",
    "grid_cv_DecisionTree = GridSearchCV(DecisionTreeRegressor(), parameters_DecisionTree, scoring = 'r2', cv = 2)\n",
    "grid_cv_DecisionTree.fit(df_train[feat_cols].fillna(df_train[feat_cols].mean()),df_train[label])\n",
    "print(grid_cv_DecisionTree.best_score_)\n",
    "print('')\n",
    "print(grid_cv_DecisionTree.best_params_)\n",
    "print('')\n",
    "print(grid_cv_DecisionTree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth 10.\n",
      "Decision tree on train sample. R2 0.010.\n",
      "Dчecision tree on valid sample. R2 -0.014.\n"
     ]
    }
   ],
   "source": [
    "train_pred = grid_cv_DecisionTree.best_estimator_.predict(new_df_train[feat_cols])\n",
    "valid_pred = grid_cv_DecisionTree.best_estimator_.predict(new_df_valid[feat_cols])\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(f'Tree depth {dc.tree_.max_depth}.')\n",
    "print(f'Decision tree on train sample. R2 {r2_score_train:.3f}.')\n",
    "print(f'Dчecision tree on valid sample. R2 {r2_score_valid:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest on train sample. R2 0.016.\n",
      "Random forest on valid sample. R2 -0.050.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=150, max_depth=5)\n",
    "\n",
    "rf.fit(new_df_train[feat_cols],new_df_train[label])\n",
    "\n",
    "train_pred = rf.predict(new_df_train[feat_cols])\n",
    "valid_pred = rf.predict(new_df_valid[feat_cols])\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(f'Random forest on train sample. R2 {r2_score_train:.3f}.')\n",
    "print(f'Random forest on valid sample. R2 {r2_score_valid:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_RandomForest = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': np.arange(2,15,4),\n",
    "    'min_samples_leaf': np.exp(np.linspace(3,8,5)).astype(int),\n",
    "    'max_features': ['sqrt', 'log2', None], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.020070739485257838\n",
      "\n",
      "{'max_depth': 14, 'max_features': 'sqrt', 'min_samples_leaf': 70, 'n_estimators': 100}\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=14,\n",
      "           max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=70, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "grid_cv_RandomForest = GridSearchCV(RandomForestRegressor(), parameters_RandomForest, scoring = 'r2', cv = 2)\n",
    "grid_cv_RandomForest.fit(new_df_train[feat_cols],new_df_train[label])\n",
    "print(grid_cv_RandomForest.best_score_)\n",
    "print('')\n",
    "print(grid_cv_RandomForest.best_params_)\n",
    "print('')\n",
    "print(grid_cv_RandomForest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree on train sample. R2 0.033.\n",
      "Decision tree on valid sample. R2 -0.005.\n"
     ]
    }
   ],
   "source": [
    "train_pred = grid_cv_RandomForest.best_estimator_.predict(new_df_train[feat_cols])\n",
    "valid_pred = grid_cv_RandomForest.best_estimator_.predict(new_df_valid[feat_cols])\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(f'Decision tree on train sample. R2 {r2_score_train:.3f}.')\n",
    "print(f'Decision tree on valid sample. R2 {r2_score_valid:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm on train sample. R2 0.036.\n",
      "gbm on valid sample. R2 -0.005.\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(new_df_train[feat_cols], df_train[label])\n",
    "lgb_eval = lgb.Dataset(new_df_valid[feat_cols], df_valid[label], reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=50,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval = False\n",
    "           )\n",
    "\n",
    "train_pred = gbm.predict(new_df_train[feat_cols], num_iteration=gbm.best_iteration)\n",
    "valid_pred = gbm.predict(new_df_valid[feat_cols], num_iteration=gbm.best_iteration)\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(f'gbm on train sample. R2 {r2_score_train:.3f}.')\n",
    "print(f'gbm on valid sample. R2 {r2_score_valid:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': ['train'],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['regression'],\n",
    "    'metric': [{'l2'}],\n",
    "    'num_leaves': [31],\n",
    "    'learning_rate': [0.05],\n",
    "    'bagging_fraction': [0.8],\n",
    "    'bagging_freq': [5],\n",
    "    'verbose': [1],\n",
    "    'max_depth': np.arange(2,15,4),\n",
    "    'min_data_in_leaf': np.exp(np.linspace(3,8,5)).astype(int),\n",
    "    'feature_fraction': [0.1, 0.3, 0.6, 0.9],\n",
    "    'n_estimators': [120]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, grid):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(new_df_train[feat_cols], new_df_train[label])\n",
    "    lgb_eval = lgb.Dataset(new_df_valid[feat_cols], new_df_valid[label], reference=lgb_train)\n",
    "    \n",
    "    result = {'params':[],'r2_train':[],'r2_valid':[]}\n",
    "    for param_values in itertools.product(*grid.values()):\n",
    "        param = dict(zip(grid.keys(),param_values))\n",
    "        if model == 'gbm':\n",
    "            gbm = lgb.train(param,\n",
    "                lgb_train,\n",
    "                num_boost_round=50,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval = False\n",
    "           )\n",
    "            train_pred = gbm.predict(new_df_train[feat_cols], num_iteration=gbm.best_iteration)\n",
    "            valid_pred = gbm.predict(new_df_valid[feat_cols], num_iteration=gbm.best_iteration)\n",
    "            r2_train = r2_score(new_df_train[label],train_pred)\n",
    "            r2_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "            result['params'].append(param)\n",
    "            result['r2_train'].append(r2_train)\n",
    "            result['r2_valid'].append(r2_valid)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = grid_search('gbm', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим результаты    \n",
    "pandas_result = (pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'task': 'train', 'boosting_type': 'gbdt', 'ob...</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>-0.007972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'task': 'train', 'boosting_type': 'gbdt', 'ob...</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>-0.004726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'task': 'train', 'boosting_type': 'gbdt', 'ob...</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>-0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'task': 'train', 'boosting_type': 'gbdt', 'ob...</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>-0.003527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'task': 'train', 'boosting_type': 'gbdt', 'ob...</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>-0.008198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  r2_train  r2_valid\n",
       "0  {'task': 'train', 'boosting_type': 'gbdt', 'ob...  0.010191 -0.007972\n",
       "1  {'task': 'train', 'boosting_type': 'gbdt', 'ob...  0.012757 -0.004726\n",
       "2  {'task': 'train', 'boosting_type': 'gbdt', 'ob...  0.012978 -0.002895\n",
       "3  {'task': 'train', 'boosting_type': 'gbdt', 'ob...  0.013115 -0.003527\n",
       "4  {'task': 'train', 'boosting_type': 'gbdt', 'ob...  0.010133 -0.008198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params      {'task': 'train', 'boosting_type': 'gbdt', 'ob...\n",
       "r2_train                                            0.0205641\n",
       "r2_valid                                          2.24135e-05\n",
       "Name: 34, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result.loc[pandas_result['r2_valid'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_of_best = pandas_result.loc[pandas_result['r2_valid'].idxmax()]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'train',\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'regression',\n",
       " 'metric': {'l2'},\n",
       " 'num_leaves': 31,\n",
       " 'learning_rate': 0.05,\n",
       " 'bagging_fraction': 0.8,\n",
       " 'bagging_freq': 5,\n",
       " 'verbose': 1,\n",
       " 'max_depth': 6,\n",
       " 'min_data_in_leaf': 854,\n",
       " 'feature_fraction': 0.6,\n",
       " 'n_estimators': 120}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_of_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Промежуточный вывод\n",
    "- Как видим, перебор параметров при данной предобработке не дает ничего хорошего\n",
    "- Далее будет экспериментировать с предобработкой признаков и перебором параметров\n",
    "- Сосредоточимся на случайном лесе и градиентном бустинге\n",
    "- В конечный CSV файл добавим прогноз этих двух моделей\n",
    "- Или одной лучшей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание NPV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сосредоточимся на градиентном бустинге и random forest\n",
    "- Поменяем кодирование категориальных признаков (выбрал BaseN)\n",
    "- Иначе заполним пропуски\n",
    "- Не будем учитывать все признаки (Смотрим на прошлую часть задания и убираем наихудшие по перемешиванию)\n",
    "- Добавим новые (Смотрел комбинации категориальных, стало хуже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = 'data'\n",
    "df = pd.read_csv(os.path.join(dump_path,'train_m.csv'))\n",
    "df_test = pd.read_csv(os.path.join(dump_path,'test_wo_labels_m.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_feats = ['add_base_flg', 's1_last_dates',  's1_prev_dates',  's1_request_flg', 'first_inc_call_dates', \n",
    "                   'first_out_call_dates', 's2_last_dates', 's2_prev_dates', 's2_request_flg', 'inc_call_cnt',\n",
    "                   'last_inc_call_dates', 'last_out_call_dates', 's3_last_dates','s3_prev_dates', 's3_request_flg',\n",
    "                   'out_call_cnt', 'prev_load_cnt', 'prev_load_dates', 'prev_s2s1', 'prev_s2s2', 'prev_s3s1', \n",
    "                   'prev_s3s2', 'prev_s1s1', 's2s1', 's2s2', 'skp_base_flg', 's3s1', 's3s2', 's1s1',\n",
    "                   'user_contact_base_flg', 's3_available_flg', 's2_available_flg', 's1_available_flg']\n",
    "\n",
    "categ_feats = ['utm_campaign', 'region', 'mob_provider', 'prev_load_status']\n",
    "\n",
    "label = 'npv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "df_train = df.query('finish_dttm <  \"2018-03-30\"')\n",
    "df_valid = df.query('finish_dttm >= \"2018-03-30\"')\n",
    "#df_train, df_valid = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = df_train.columns\n",
    "st = set(df_train.columns)\n",
    "for i in df_test.columns:\n",
    "    for j in df_train.columns:\n",
    "        if i == j:\n",
    "            st.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application_flg', 'decision_approve_flg', 'init_cost', 'npv'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = set(important_feats)\n",
    "important_feats.remove('application_flg')\n",
    "important_feats.remove('decision_approve_flg')\n",
    "important_feats.remove('init_cost')\n",
    "important_feats.remove('npv')\n",
    "important_feats = list(important_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseNEncoder(base=6,\n",
       "       cols=['utm_campaign', 'region', 'mob_provider', 'prev_load_status'],\n",
       "       drop_invariant=False, handle_unknown='impute', impute_missing=True,\n",
       "       return_df=True, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders import BaseNEncoder\n",
    "from category_encoders import OneHotEncoder\n",
    "enc = BaseNEncoder(cols=categ_feats, base=6)\n",
    "#enc = OneHotEncoder(cols = categ_feats)\n",
    "enc.fit(df_train[important_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label = df_train[label]\n",
    "df_valid_label = df_valid[label]\n",
    "df_train = df_train[important_feats]\n",
    "df_valid = df_valid[important_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = enc.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = enc.transform(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "for i in df_train.columns:\n",
    "    if i != 'npv' and i != 'create_dt' and i != 'finish_dttm' and i not in st and i != 's3_last_dates' and i != 'prev_s2s1' and i != 'first_out_call_dates' and i != 'prev_s2s2' and i != 's1_prev_dates':\n",
    "        feat_cols.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = df_train[feat_cols].fillna(df_train[feat_cols].mean())\n",
    "new_df_valid = df_valid[feat_cols].fillna(df_train[feat_cols].mean())\n",
    "new_df_train[label] = df_train_label\n",
    "new_df_valid[label] = df_valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[label] = df_train_label\n",
    "df_valid[label] = df_valid_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:102: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04380944510424056\n",
      "0.003251619767259517\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(new_df_train[feat_cols], new_df_train[label])\n",
    "lgb_eval = lgb.Dataset(new_df_valid[feat_cols], new_df_valid[label], reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'n_estimators': 115,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=50,\n",
    "                valid_sets=lgb_train,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval = False\n",
    "           )\n",
    "\n",
    "train_pred = gbm.predict(new_df_train[feat_cols], num_iteration=gbm.best_iteration)\n",
    "valid_pred = gbm.predict(new_df_valid[feat_cols], num_iteration=gbm.best_iteration)\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(r2_score_train)\n",
    "print(r2_score_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, grid):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(new_df_train[feat_cols], new_df_train[label])\n",
    "    lgb_eval = lgb.Dataset(new_df_valid[feat_cols], new_df_valid[label], reference=lgb_train)\n",
    "    \n",
    "    result = {'params':[],'r2_train':[],'r2_valid':[]}\n",
    "    for param_values in itertools.product(*grid.values()):\n",
    "        param = dict(zip(grid.keys(),param_values))\n",
    "        if model == 'gbm':\n",
    "            gbm = lgb.train(param,\n",
    "                lgb_train,\n",
    "                num_boost_round=50,\n",
    "                valid_sets=lgb_train,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval = False\n",
    "           )\n",
    "            train_pred = gbm.predict(new_df_train[feat_cols], num_iteration=gbm.best_iteration)\n",
    "            valid_pred = gbm.predict(new_df_valid[feat_cols], num_iteration=gbm.best_iteration)\n",
    "            r2_train = r2_score(new_df_train[label],train_pred)\n",
    "            r2_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "            result['params'].append(param)\n",
    "            result['r2_train'].append(r2_train)\n",
    "            result['r2_valid'].append(r2_valid)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': ['train'],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['regression'],\n",
    "    'metric': [{'l2'}],\n",
    "    'num_leaves': [31],\n",
    "    'learning_rate': [0.05],\n",
    "    'bagging_fraction': [0.8],\n",
    "    'bagging_freq': [5],\n",
    "    'verbose': [1],\n",
    "    'max_depth': np.arange(2,15,4),\n",
    "    'min_data_in_leaf': np.exp(np.linspace(3,8,5)).astype(int),\n",
    "    'feature_fraction': [0.1, 0.3, 0.6, 0.9],\n",
    "    'n_estimators': [114]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:102: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 8s, sys: 1min 2s, total: 25min 11s\n",
      "Wall time: 8min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = grid_search('gbm', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим результаты    \n",
    "pandas_result = (pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params      {'task': 'train', 'boosting_type': 'gbdt', 'ob...\n",
       "r2_train                                            0.0222979\n",
       "r2_valid                                            0.0041399\n",
       "Name: 34, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result.loc[pandas_result['r2_valid'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_of_best = pandas_result.loc[pandas_result['r2_valid'].idxmax()]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8,\n",
       " 'bagging_freq': 5,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'feature_fraction': 0.6,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 6,\n",
       " 'metric': {'l2'},\n",
       " 'min_data_in_leaf': 854,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'regression',\n",
       " 'task': 'train',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_of_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:102: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02216903725609809\n",
      "0.003361569411432397\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(new_df_train[feat_cols], new_df_train[label])\n",
    "lgb_eval = lgb.Dataset(new_df_valid[feat_cols], new_df_valid[label], reference=lgb_train)\n",
    "\n",
    "params = {'bagging_fraction': 0.8,\n",
    " 'bagging_freq': 5,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'feature_fraction': 0.6,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 6,\n",
    " 'metric': {'l2'},\n",
    " 'min_data_in_leaf': 854,\n",
    " 'num_leaves': 31,\n",
    " 'objective': 'regression',\n",
    " 'task': 'train',\n",
    " 'verbose': 1,\n",
    "'n_estimators':114}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=50,\n",
    "                valid_sets=lgb_train,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval = False,\n",
    "           )\n",
    "\n",
    "train_pred = gbm.predict(new_df_train[feat_cols], num_iteration=gbm.best_iteration)\n",
    "valid_pred = gbm.predict(new_df_valid[feat_cols], num_iteration=gbm.best_iteration)\n",
    "\n",
    "r2_score_train = r2_score(new_df_train[label],train_pred)\n",
    "r2_score_valid = r2_score(new_df_valid[label],valid_pred)\n",
    "\n",
    "print(r2_score_train)\n",
    "print(r2_score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Это был эксперимент, теперь загружаем данные заново и учим модель на всем df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = 'data'\n",
    "df = pd.read_csv(os.path.join(dump_path,'train_m.csv'))\n",
    "df_test = pd.read_csv(os.path.join(dump_path,'test_wo_labels_m.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_feats = ['add_base_flg', 's1_last_dates',  's1_prev_dates',  's1_request_flg', 'first_inc_call_dates', \n",
    "                   'first_out_call_dates', 's2_last_dates', 's2_prev_dates', 's2_request_flg', 'inc_call_cnt',\n",
    "                   'last_inc_call_dates', 'last_out_call_dates', 's3_last_dates','s3_prev_dates', 's3_request_flg',\n",
    "                   'out_call_cnt', 'prev_load_cnt', 'prev_load_dates', 'prev_s2s1', 'prev_s2s2', 'prev_s3s1', \n",
    "                   'prev_s3s2', 'prev_s1s1', 's2s1', 's2s2', 'skp_base_flg', 's3s1', 's3s2', 's1s1',\n",
    "                   'user_contact_base_flg', 's3_available_flg', 's2_available_flg', 's1_available_flg']\n",
    "\n",
    "categ_feats = ['utm_campaign', 'region', 'mob_provider', 'prev_load_status']\n",
    "\n",
    "label = 'npv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = df.columns\n",
    "st = set(df.columns)\n",
    "for i in df_test.columns:\n",
    "    for j in df.columns:\n",
    "        if i == j:\n",
    "            st.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application_flg', 'decision_approve_flg', 'init_cost', 'npv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = set(important_feats)\n",
    "important_feats.remove('application_flg')\n",
    "important_feats.remove('decision_approve_flg')\n",
    "important_feats.remove('init_cost')\n",
    "important_feats.remove('npv')\n",
    "important_feats = list(important_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseNEncoder(base=6,\n",
       "       cols=['utm_campaign', 'region', 'mob_provider', 'prev_load_status'],\n",
       "       drop_invariant=False, handle_unknown='impute', impute_missing=True,\n",
       "       return_df=True, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders import BaseNEncoder\n",
    "from category_encoders import OneHotEncoder\n",
    "enc = BaseNEncoder(cols=categ_feats, base=6)\n",
    "#enc = OneHotEncoder(cols = categ_feats)\n",
    "enc.fit(df[important_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df[label]\n",
    "df = df[important_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enc.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "for i in df.columns:\n",
    "    if i != 'npv' and i != 'create_dt' and i != 'finish_dttm' and i not in st and i != 's3_last_dates' and i != 'prev_s2s1' and i != 'first_out_call_dates' and i != 'prev_s2s2' and i != 's1_prev_dates':\n",
    "        feat_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[feat_cols].fillna(df[feat_cols].mean())\n",
    "new_df[label] = df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:102: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023858856943278606\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(new_df[feat_cols], new_df[label])\n",
    "\n",
    "params = {'bagging_fraction': 0.8,\n",
    " 'bagging_freq': 5,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'feature_fraction': 0.6,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 6,\n",
    " 'metric': {'l2'},\n",
    " 'min_data_in_leaf': 854,\n",
    " 'num_leaves': 31,\n",
    " 'objective': 'regression',\n",
    " 'task': 'train',\n",
    " 'verbose': 1,\n",
    "'n_estimators':114}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=50,\n",
    "                valid_sets=lgb_train,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval = False,\n",
    "           )\n",
    "\n",
    "train_pred = gbm.predict(new_df[feat_cols], num_iteration=gbm.best_iteration)\n",
    "\n",
    "r2_score_train = r2_score(new_df[label],train_pred)\n",
    "\n",
    "print(r2_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка и предсказание для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = enc.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test = df_test[feat_cols].fillna(df[feat_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gbm.predict(new_df_test[feat_cols], num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_predict_m.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_m = pd.DataFrame(test_pred, columns=['npv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['decision_tree_predict'] = <your code here>\n",
    "#df_test['random_forest_predict'] = <your code here>\n",
    "df_test['lgbm_predict'] = test_predict_m\n",
    "\n",
    "df_test['student_name'] = 'a.polyakov'  # Поменяйте на свои имя фамилию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['hl_rk','lgbm_predict','student_name']].to_csv(\n",
    "    os.path.join(dump_path,'test_predict_m.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('data/test_predict_m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
